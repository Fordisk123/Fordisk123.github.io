# MongoDB技术分享

**一、MongoDB是什么：**


MongoDB是一个基于分布式文档存储的数据库。由[C++](https://baike.baidu.com/item/C%2B%2B)语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。
MongoDB是一个介于[关系数据库](https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93)和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似[json](https://baike.baidu.com/item/json)的[bson](https://baike.baidu.com/item/bson)格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立[索引](https://baike.baidu.com/item/%E7%B4%A2%E5%BC%95)。
MongoDB是一个NOSQL数据库。




**二、NoSQL数据库有哪些**
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585623789096-cca977d4-c8c9-4486-b8c3-948db9077203.png#align=left&display=inline&height=291&name=image.png&originHeight=290&originWidth=653&size=24821&status=done&style=none&width=655)




**三、MongoDB设计架构图**
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585623891709-9fcb7cc8-0126-4c79-a05a-7a70e0b7f097.png#align=left&display=inline&height=202&name=image.png&originHeight=281&originWidth=950&size=168907&status=done&style=none&width=684)
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585623900751-e626c03f-9266-40bd-af17-4eb89dd1756d.png#align=left&display=inline&height=272&name=image.png&originHeight=379&originWidth=950&size=251692&status=done&style=none&width=682)




**四、WiredTiger存储引擎**
**
**  1、为什么使用WiredTiger引擎
**
因为MMAP存储引擎自身的天然缺陷（耗费磁盘空间和 内存空间且难以清理，库级别锁），MongoDB为数据库运维人员带来了极大痛苦，因此MongoDB直接收购存储引擎厂商WiredTiger，将WiredTiger存储引擎集成进3.0版本。

**  2、WiredTirger存储引擎的优势：**
**
**    2.1、文档级别并发控制**
    WiredTiger 通过MVCC实现文档级别的并发控制，即文档级别锁。这就允许多个客户端请求同时更新一个集合内存的多个文档，再也不需要在排队等待 库级别的写锁。
    ![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585624660008-5aef6999-9be8-4085-a8ef-b19c96ab262a.png#align=left&display=inline&height=486&name=image.png&originHeight=685&originWidth=950&size=248098&status=done&style=none&width=674)
**    2.2、磁盘数据压缩**
    WiredTiger 支持对所有集合和索引进行Block压缩和前缀压缩（如果数据库启用了journal，journal文件一样会压缩），已支持的压 缩选项包括：不压缩、Snappy压缩和Zlib压缩。

**    2.3、可配置内存使用上限**
WiredTiger 支持内存使用容量配置，用户通过storage.wiredTiger.engineConfig.cacheSizeGB参数即可 控制MongoDB所能使用的最大内存，该参数默认值为物理内存大小的一半。

**
**  3、WiredTiger存储引擎的工作原理：**
**
**![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585625322460-29ec3961-aaf5-4aa4-a410-f8395f967a5b.png#align=left&display=inline&height=182&name=image.png&originHeight=350&originWidth=1000&size=85757&status=done&style=none&width=521)**
**
**
**    3.1、Mongodb数据写入流程**
1、wiredTiger写操作先到cache，并持久化WAL
2、每60s或log文件达到2G，则执行一次Checkpoint持久化，产生一个新快照。
3、wiredTiger连接初始化时，先将数据恢复到最新的快照，再根据WAL恢复数据。

**    3.2、Cache**
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585625579389-b6c7ff2e-86e8-4f33-a507-5d51fbb17651.png#align=left&display=inline&height=361&name=image.png&originHeight=389&originWidth=521&size=110309&status=done&style=none&width=484)

Cache采用Btree方式组织，每个Btree节点为一个page，数据以page为单位按需从磁盘加载或写入磁盘
root page：Btree的根节点
internal page：中间索引节点
page：叶子节点，数据存储在此节点。


**为什么Mongodb使用B-Tree？**
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585884567839-0327fa64-174b-4851-ae0f-28cd01ee853a.png#align=left&display=inline&height=238&name=image.png&originHeight=475&originWidth=950&size=129664&status=done&style=none&width=475)
B+ Tree


```
对比Mysql采用的B+ Tree,由于B+Tree只在叶子节点存储数据，
任意一次查询所需要的的时间都是O(log n),性能非常稳定，但是增加了磁盘IO总量，
MongoDb使用B-Tree，索引节点存储数据,查询时间不恒定，最快O(1)即一次命中索引，尽量减少磁盘IO
是提高性能的有效手段，由于Monodb是文档型数据库，不推荐连表查询（大量的区间遍历），
所以使用B-Tree作为索引结构,查询中减少磁盘IO总量的优化策略
```


**    3.3、COW(Copy on write)**
采用Copy on write的方式管理insert、update、delete。
1、数据读入Cache里，
2、对数据修改，
3、持久化时，写入新的page(不会写原leaf page)。
4、执行Chechpoint之后，产生新的page。


**    3.4、Checkpoints
**
1、对所有的table进行一次Checkpoint，将每个table的Checkpoint的元数据更新到WiredTiger.wt
2、再对WiredTiger.wt进行Checkpoint，将Checkpoint的meta数据更新到WiredTiger.turtle.set
3、将WiredTiger.turtle.set重命名为WiredTiger.turtle




**五、使用Golang操作MongoDb**


```go
package main

import (
	"fmt"
	"go.mongodb.org/mongo-driver/bson"
	"go.mongodb.org/mongo-driver/bson/primitive"
	"go.mongodb.org/mongo-driver/mongo"
	"go.mongodb.org/mongo-driver/mongo/options"
	"golang.org/x/net/context"
	"time"
)

type Person struct {
	Id   primitive.ObjectID `bson:"_id,omitempty"`
	Name string `bson:"name,omitempty"`
	Age  int `bson:"age,omitempty"`
	Born time.Time `bson:"born,omitempty"`
	Hobby []string `bson:"hobby,omitempty"`
	Transcript `bson:"transcript,omitempty"`
}

type Transcript struct {
	Math    float32 `bson:"math,omitempty"`
	English float32 `bson:"english,omitempty"`
	Chinese float32 `bson:"chinese,omitempty"`
}

func main() {

	person := Person{
		Name:       "xiaoming",
		Age:        18,
		Born:       time.Now(),
		Hobby:      []string{"game", "ball"},
		Transcript: Transcript{
			Math:    90,
			English: 60,
			Chinese: 70,
		},
	}

	ctx, _ := context.WithTimeout(context.Background(), 10*time.Second)
	client, err := mongo.Connect(ctx, options.Client().ApplyURI("mongodb://root:Chison2019%21@192.168.55.116/test?authSource=admin"))
	if err != nil{
		fmt.Println(err)
		return
	}

	collection := client.Database("test").Collection("person")
	ctx, _ = context.WithTimeout(context.Background(), 5*time.Second)
	var id primitive.ObjectID

	for i := 0 ; i < 10 ; i++{
		res, err := collection.InsertOne(ctx, person)
		if err != nil{
			fmt.Println(err)
			return
		}
		id = res.InsertedID.(primitive.ObjectID)
	}

	fmt.Printf("Res id : %s\n" , id.Hex())

	//select by id
	fmt.Println("------------------------ select one by id ------------------------")
	ctx, _ = context.WithTimeout(context.Background(), 5*time.Second)
	filter := bson.M{"_id" : id}
	err = collection.FindOne(ctx , filter).Decode(&person)
	if err != nil{
		panic(err)
	}
	fmt.Println(person)

	//update
	fmt.Println("------------------------ update ------------------------")
	ctx, _ = context.WithTimeout(context.Background(), 100*time.Second)
	person.Name = "xiaohong"
	person.Chinese = 100
	person.Hobby = []string{"read" , "dance"}
	updateRes , err := collection.UpdateMany(ctx , filter , bson.M{"$set" : person})
	if err != nil{
		panic(err)
	}
	fmt.Printf("Updated records count : %d \n" , updateRes.ModifiedCount)

	//select all
	fmt.Println("------------------------ select all ------------------------")
	ctx, _ = context.WithTimeout(context.Background(), 5*time.Second)
	var personList []Person
	allRes , err := collection.Find(ctx , bson.M{})
	if err != nil{
		fmt.Println(err)
		return
	}
	err = allRes.All(ctx , &personList)
	if err != nil{
		fmt.Println(err)
		return
	}

	for _ , person := range personList{
		fmt.Println(person)
	}

	//aggregate
	fmt.Println("------------------------ aggregate ------------------------")
	ctx, _ = context.WithTimeout(context.Background(), 10*time.Second)
	matchPipe := bson.D{
		{"$match" ,  bson.M{
			"transcript.chinese" : bson.M{
				"$gte" : 90,
			},
		},
		},
	}
	showInfoCursor, err := collection.Aggregate(ctx , mongo.Pipeline{matchPipe})
	if err != nil {
		panic(err)
	}
	if err = showInfoCursor.All(ctx, &personList); err != nil {
		panic(err)
	}
	for _ , person := range personList{
		fmt.Println(person)
	}

	//delete
	fmt.Println("------------------------ delete ------------------------")
	ctx, _ = context.WithTimeout(context.Background(), 10*time.Second)
	filter = bson.M{"age" : 18}
	delRes , err := collection.DeleteMany(ctx , filter)
	if err != nil {
		panic(err)
	}
	fmt.Printf("Deleted records count : %d \n" , delRes.DeletedCount)
}

```




**六、MongoDB集群**
**   6.1、集群架构**
**
**![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585886172265-1eb429d9-d9d1-4b54-9cf6-fa6d8a9175b4.png#align=left&display=inline&height=220&name=image.png&originHeight=440&originWidth=620&size=35272&status=done&style=none&width=310)**
 （1）mongos ：数据路由，和客户端打交道的模块。mongos本身没有任何数据，他也不知道该怎么处理这数据，去找config server
（2）config server：所有存、取数据的方式，所有shard节点的信息，分片功能的一些配置信息。可以理解为真实数据的元数据。
 （3）shard：真正的数据存储位置，以chunk为单位存数据。


在每个Shard中，数据以chunk的形式来存储：

- 进群搭建完成之后，默认开启一个chunk，大小是64M，
- 存储需求超过64M，chunk会进行分裂，如果单位时间存储需求很大，设置更大的chunk
- chunk会被自动均衡迁移。

**
**![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585886661451-9e5126f2-b392-4b7b-a366-5471fdb67a09.png#align=left&display=inline&height=164&name=image.png&originHeight=327&originWidth=451&size=49922&status=done&style=none&width=225.5)![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585886667430-0a234372-b8b7-4c87-90c6-15996af1d16d.png#align=left&display=inline&height=151&name=image.png&originHeight=302&originWidth=771&size=66132&status=done&style=none&width=385.5)**
Chunk的默认值是64MB，可取值范围是 1 ~ 1024M，下图总结了chunk值修改的利弊：
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585894985408-8aee25dc-6cb8-4542-8d39-5aa60fbd13b6.png#align=left&display=inline&height=175&name=image.png&originHeight=289&originWidth=1093&size=49288&status=done&style=none&width=665)


**   6.2、Sharding Key 分片键**
    MongoDB中数据的分片是以集合为基本单位的，集合中的数据通过片键（Shard key）被分成多部分。其实片键就是在集合中选一个键，用该键的值作为数据拆分的依据。MongoDB使用**基于范围的分片**方式或者 **基于哈希的分片方式**。

- 分片键是不可变。
- 分片键必须有索引。
- 分片键大小限制512bytes。
- 分片键用于路由查询。
- MongoDB不接受已进行collection级分片的collection上插入无分片
- 键的文档（也不支持空值插入）



 
![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585889217291-d18d431e-4ef1-474e-bf74-23d6e234fa82.png#align=left&display=inline&height=239&name=image.png&originHeight=280&originWidth=771&size=60268&status=done&style=none&width=657)
范围分片


![image.png](https://cdn.nlark.com/yuque/0/2020/png/915396/1585889222938-e29cd6e7-9000-4971-9a45-9c2fe3859a77.png#align=left&display=inline&height=247&name=image.png&originHeight=288&originWidth=772&size=48967&status=done&style=none&width=663)
hash分片
